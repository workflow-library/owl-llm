# Example input for single prompt inference
model:
  class: File
  path: ../models/llama-2-7b-chat.Q4_K_M.gguf

prompt: "What is the capital of France?"

n_predict: 100
temperature: 0.7
top_k: 40
top_p: 0.95
threads: 4